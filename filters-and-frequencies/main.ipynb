{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0878f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.signal as scisig\n",
    "import skimage.transform as sktr\n",
    "from os import listdir\n",
    "import skimage.io as skio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48df4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the image in color or grayscale\n",
    "def read_img(imname, path=\"data\", gray=True):\n",
    "    if gray:\n",
    "        return cv2.imread(f'./{path}/{imname}', cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        return cv2.imread(f'./{path}/{imname}')\n",
    "        #return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "# Separate the image into rgb color channels\n",
    "def get_color_channels(im):\n",
    "    r = im[:,:,0]\n",
    "    g = im[:,:,1]\n",
    "    b = im[:,:,2]\n",
    "    return r, g, b\n",
    "\n",
    "# Display the image in notebook\n",
    "def show_img(img, gray=True):\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img[:,:,::-1])\n",
    "    else: \n",
    "        plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "    \n",
    "# Saves the give images as jpg files\n",
    "def save_img(imname, result):\n",
    "    cv2.imwrite(f'./output/{imname}.jpg', result)\n",
    "\n",
    "# Saves a list of images\n",
    "def save_intermediate(imgs, imname):\n",
    "    for i, im in enumerate(imgs):\n",
    "        save_img(f'{imname}-{i}',auto_contrast(im))\n",
    " \n",
    "# Contrast the image for better visualization\n",
    "def auto_contrast(img):\n",
    "    x, counts = np.unique(img, return_counts=True)\n",
    "    cusum = np.cumsum(counts)\n",
    "    pixel_mapping = {x[i]: cusum[i] / cusum[-1] * 255 for i in range(len(x))}\n",
    "    convert = np.vectorize(lambda x: pixel_mapping[x])\n",
    "    return convert(img).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f939c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'icc': 0h: PCS illuminant is not D50\n"
     ]
    }
   ],
   "source": [
    "# Part 1.1: Finite Difference Operator\n",
    "\n",
    "# Binarize the image\n",
    "def binarize(im, threshold):\n",
    "    return np.where(np.abs(im) > threshold, 255, 0)\n",
    "\n",
    "# Convolve image with gradient filter \n",
    "def img_grad(im, thresh=60):\n",
    "    dx = np.array([[1,-1], [0,0]])\n",
    "    dy = np.array([[1,-1], [0,0]]).T\n",
    "    \n",
    "    im_x = scisig.convolve2d(dx, im, mode=\"valid\")\n",
    "    im_y = scisig.convolve2d(dy, im, mode=\"valid\")\n",
    "\n",
    "    bin_x = binarize(im_x, thresh)\n",
    "    bin_y = binarize(im_y, thresh)\n",
    "    \n",
    "    return cv2.add(bin_x, bin_y)\n",
    "\n",
    "im = read_img('cameraman.png')\n",
    "result = img_grad(im)\n",
    "show_img(result)\n",
    "save_img('cameraman', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6f46d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'icc': 0h: PCS illuminant is not D50\n"
     ]
    }
   ],
   "source": [
    "# Part 1.2: Derivative of Gaussian (DoG) Filter\n",
    "\n",
    "# Blur image with Gaussian Kernel\n",
    "def gaussian_blur(im, size=5, sigma=2, mode=\"valid\"):\n",
    "    kernel = cv2.getGaussianKernel(size, sigma)\n",
    "    kernel_2d = kernel @ kernel.T\n",
    "    return scisig.convolve2d(im, kernel_2d,  mode=mode)\n",
    "\n",
    "im = read_img('cameraman.png')\n",
    "blurred = gaussian_blur(im)\n",
    "result = img_grad(blurred, thresh=20)\n",
    "\n",
    "show_img(result)\n",
    "save_img('cameraman_blurred', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2509fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.1: Image \"Sharpening\"\n",
    "\n",
    "# Extract high frequencies from image\n",
    "def high_pass_filter(im, size=7, sigma=2):\n",
    "    s = int(size/2)\n",
    "    blurred = gaussian_blur(im, size, sigma)\n",
    "    if size%2 == 0:\n",
    "        im = im[s:len(im)-s, s:len(im)-s]\n",
    "    else:\n",
    "        im = im[s:len(im)-s, s:len(im[0])-s]\n",
    "    high_freq = im - blurred\n",
    "    return high_freq, im\n",
    "\n",
    "# Sharpen image\n",
    "def unsharp_mask_filter(im, alpha=6):\n",
    "    high_freq, im = high_pass_filter(im)\n",
    "    result = im + alpha * high_freq\n",
    "    return result\n",
    "\n",
    "imname = 'bellagio'\n",
    "im = read_img(f'{imname}.jpeg', gray=False)\n",
    "r,g,b = get_color_channels(im)\n",
    "\n",
    "r_sharp = unsharp_mask_filter(r)\n",
    "g_sharp = unsharp_mask_filter(g)\n",
    "b_sharp = unsharp_mask_filter(b)\n",
    "\n",
    "result = np.dstack([r_sharp, g_sharp, b_sharp])\n",
    "save_img(f'sharp_{imname}', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a83c9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to reshapren already sharp image\n",
    "im = read_img('landscape.jpeg', gray=False)\n",
    "\n",
    "r,g,b = get_color_channels(im)\n",
    "\n",
    "r_blur = gaussian_blur(r)\n",
    "g_blur = gaussian_blur(g)\n",
    "b_blur = gaussian_blur(b)\n",
    "\n",
    "r_sharp = unsharp_mask_filter(r_blur)\n",
    "g_sharp = unsharp_mask_filter(g_blur)\n",
    "b_sharp = unsharp_mask_filter(b_blur)\n",
    "\n",
    "result = np.dstack([r_sharp, g_sharp, b_sharp])\n",
    "#save_img('resharpened', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a53cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.2: Hybrid Images\n",
    "# This cell contains all the given helper methods\n",
    "\n",
    "def get_points(im1, im2):\n",
    "    print('Please select 2 points in each image for alignment.')\n",
    "    plt.imshow(im1)\n",
    "    p1, p2 = plt.ginput(2)\n",
    "    plt.close()\n",
    "    plt.imshow(im2)\n",
    "    p3, p4 = plt.ginput(2)\n",
    "    plt.close()\n",
    "    return (p1, p2, p3, p4)\n",
    "\n",
    "def recenter(im, r, c):\n",
    "    R, C = im.shape\n",
    "    rpad = (int) (np.abs(2*r+1 - R))\n",
    "    cpad = (int) (np.abs(2*c+1 - C))\n",
    "    return np.pad(\n",
    "        im, [(0 if r > (R-1)/2 else rpad, 0 if r < (R-1)/2 else rpad),\n",
    "             (0 if c > (C-1)/2 else cpad, 0 if c < (C-1)/2 else cpad),],\n",
    "            'constant')\n",
    "\n",
    "def find_centers(p1, p2):\n",
    "    cx = np.round(np.mean([p1[0], p2[0]]))\n",
    "    cy = np.round(np.mean([p1[1], p2[1]]))\n",
    "    return cx, cy\n",
    "\n",
    "def align_image_centers(im1, im2, pts):\n",
    "    p1, p2, p3, p4 = pts\n",
    "    h1, w1 = im1.shape\n",
    "    h2, w2 = im2.shape\n",
    "    \n",
    "    cx1, cy1 = find_centers(p1, p2)\n",
    "    cx2, cy2 = find_centers(p3, p4)\n",
    "\n",
    "    im1 = recenter(im1, cy1, cx1)\n",
    "    im2 = recenter(im2, cy2, cx2)\n",
    "    return im1, im2\n",
    "\n",
    "def rescale_images(im1, im2, pts):\n",
    "    p1, p2, p3, p4 = pts\n",
    "    len1 = np.sqrt((p2[1] - p1[1])**2 + (p2[0] - p1[0])**2)\n",
    "    len2 = np.sqrt((p4[1] - p3[1])**2 + (p4[0] - p3[0])**2)\n",
    "    dscale = len2/len1\n",
    "    dscale_tuple = (1./dscale, 1./dscale)\n",
    "    if dscale < 1:\n",
    "        im1 = sktr.rescale(im1, dscale_tuple)\n",
    "    else:\n",
    "        im2 = sktr.rescale(im2, dscale_tuple)\n",
    "    return im1, im2\n",
    "\n",
    "def rotate_im1(im1, im2, pts):\n",
    "    p1, p2, p3, p4 = pts\n",
    "    theta1 = math.atan2(-(p2[1] - p1[1]), (p2[0] - p1[0]))\n",
    "    theta2 = math.atan2(-(p4[1] - p3[1]), (p4[0] - p3[0]))\n",
    "    dtheta = theta2 - theta1\n",
    "    im1 = sktr.rotate(im1, dtheta*180/np.pi)\n",
    "    return im1, dtheta\n",
    "\n",
    "def match_img_size(im1, im2):\n",
    "    # Make images the same size\n",
    "    h1, w1 = im1.shape\n",
    "    h2, w2 = im2.shape\n",
    "    if h1 < h2:\n",
    "        im2 = im2[int(np.floor((h2-h1)/2.)) : -int(np.ceil((h2-h1)/2.)), :]\n",
    "    elif h1 > h2:\n",
    "        im1 = im1[int(np.floor((h1-h2)/2.)) : -int(np.ceil((h1-h2)/2.)), :]\n",
    "    if w1 < w2:\n",
    "        im2 = im2[:, int(np.floor((w2-w1)/2.)) : -int(np.ceil((w2-w1)/2.))]\n",
    "    elif w1 > w2:\n",
    "        im1 = im1[:, int(np.floor((w1-w2)/2.)) : -int(np.ceil((w1-w2)/2.))]\n",
    "    assert im1.shape == im2.shape\n",
    "    return im1, im2\n",
    "\n",
    "def align_images(im1, im2):\n",
    "    pts = get_points(im1, im2)\n",
    "    im1, im2 = align_image_centers(im1, im2, pts)\n",
    "    im1, im2 = rescale_images(im1, im2, pts)\n",
    "    im1, angle = rotate_im1(im1, im2, pts)\n",
    "    im1, im2 = match_img_size(im1, im2)\n",
    "    return im1, im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b929f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.2: Continued\n",
    "\n",
    "# Creates hybrid image\n",
    "def create_hybrid(im1, im2, size1=30, sigma1=20, size2=31, sigma2=20):\n",
    "    im1 = gaussian_blur(im1, size=size1, sigma=sigma1)\n",
    "    im2 = high_pass_filter(im2, size=size2, sigma=sigma2)[0]\n",
    "    im1, im2 = align_images(im2, im1)\n",
    "    return im1 + im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac7d8ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select 2 points in each image for alignment.\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Image Example 1\n",
    "im1 = read_img('DerekPicture.jpg', gray=True)\n",
    "im2 = read_img('nutmeg.jpg', gray=True)\n",
    "hybrid = create_hybrid(im1, im2)\n",
    "hybrid[360:, :]\n",
    "save_img('derek_nutemeg', hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "08c8992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select 2 points in each image for alignment.\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Image Example 2\n",
    "im1 = read_img('walter.jpeg', gray=True)\n",
    "im2 = read_img('dog.jpeg', gray=True)\n",
    "hybrid = create_hybrid(im1, im2)\n",
    "save_img('walter_dog', hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a7cf34da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select 2 points in each image for alignment.\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Image Example 3\n",
    "im1 = read_img('matt.jpeg', gray=True)\n",
    "im2 = read_img('queen.jpeg', gray=True)\n",
    "hybrid = create_hybrid(im1, im2, size1=15, size2=25)\n",
    "save_img('matt_queen', hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e366b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed Hybrid Image\n",
    "im1 = read_img('leo.jpeg', gray=True)\n",
    "im2 = read_img('chris.jpeg', gray=True)\n",
    "hybrid = create_hybrid(im1, im2, size1=15, size2=31)\n",
    "save_img('leo_chris', hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8a828ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2: Frequency Analysis\n",
    "def get_freq_analysis(im):\n",
    "    x = np.log(np.abs(np.fft.fftshift(np.fft.fft2(im))))\n",
    "    x = auto_contrast(x)\n",
    "    return x\n",
    "\n",
    "im1 = read_img('walter.jpeg', gray=True)\n",
    "im2 = read_img('dog.jpeg', gray=True)\n",
    "hybrid = read_img('walter_dog.jpg')\n",
    "\n",
    "#save_img('walter_freq', get_freq_analysis(im1))\n",
    "#save_img('dog_freq', get_freq_analysis(im2))\n",
    "#save_img('hybrid_freq', get_freq_analysis(hybrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "21c1449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.3: Gaussian and Laplacian Stacks\n",
    "\n",
    "# Convolves each rgb channel with a gaussian kernel\n",
    "def convolve_colors(im, size=5, sigma=2):\n",
    "    r = gaussian_blur(im[:,:,0], size=size, sigma=sigma, mode='same')\n",
    "    g = gaussian_blur(im[:,:,1], size=size, sigma=sigma, mode='same')\n",
    "    b = gaussian_blur(im[:,:,2], size=size, sigma=sigma, mode='same')\n",
    "    res = np.dstack([r,g,b])\n",
    "    return res\n",
    "\n",
    "# Creates a gaussian stack for an image\n",
    "def gaussian_stack(im, levels=5, size=30, sigma=1):\n",
    "    gstack = [im]\n",
    "    for i in range(levels):\n",
    "        im_new = convolve_colors(gstack[i], size=size, sigma=sigma)\n",
    "        gstack.append(im_new)\n",
    "    return gstack\n",
    "\n",
    "# Creates a laplacian stack for an image\n",
    "def laplacian_stack(im):\n",
    "    lstack = []\n",
    "    gstack = gaussian_stack(im)\n",
    "    for i in range(len(gstack)-1):\n",
    "        lstack.append(gstack[i+1] - gstack[i])\n",
    "    lstack.append(gstack[-1])\n",
    "    return lstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "acb7ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4: Multiresolution Blending\n",
    "\n",
    "# Applies mask to laplacians and combines images\n",
    "def blend_layers(la, lb, gr):\n",
    "    ls = []\n",
    "    for i in range(len(la)):\n",
    "        blended =  gr[i] * la[i] + (1-gr[i]) * lb[i]\n",
    "        ls.append(blended)\n",
    "    return ls\n",
    "\n",
    "# Blends two images together given a mask\n",
    "def blend_img(im1, im2, mask):\n",
    "    la = laplacian_stack(im1)\n",
    "    lb = laplacian_stack(im2)\n",
    "    gr = gaussian_stack(mask, size=50, sigma=15)\n",
    "    ls = blend_layers(la, lb, gr)\n",
    "    return np.sum(ls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac35e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive code for Oraple\n",
    "im1 = read_img('apple.jpeg', gray=False)\n",
    "im2 = read_img('orange.jpeg', gray=False)\n",
    "\n",
    "# Create mask of half 0s and half 1s\n",
    "mask = np.zeros(im1.shape)\n",
    "mask[:, :im1.shape[1]//2] = 1\n",
    "\n",
    "result = blend_img(im1, im2, mask)\n",
    "#save_img('oraple', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7db0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code for Custom Image 1\n",
    "im1 = read_img('sathergate.jpeg', gray=False)\n",
    "im2 = read_img('bear.jpeg', gray=False)\n",
    "mask = read_img('bear_mask.png', gray=False)\n",
    "\n",
    "# Pad the smaller image and mask\n",
    "im2 = np.pad(im2, [(40,0), (225,225), (0,0)])\n",
    "mask = np.pad(mask, [(40,0), (225, 225), (0,0)], constant_values=255)\n",
    "\n",
    "# Set the mask values to 0 and 1\n",
    "mask = np.where(mask >= 255, mask, 1)\n",
    "mask = np.where(mask < 255, mask, 0)\n",
    "\n",
    "# Blend the image and save\n",
    "result = blend_img(im2, im1, mask)\n",
    "#save_img('berkeley_bear', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "961461a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code for Custom Image 2\n",
    "im1 = read_img('cal_game.jpeg', gray=False)\n",
    "im2 = read_img('great_dane.jpeg', gray=False)\n",
    "mask = read_img('dane_mask.png', gray=False)\n",
    "\n",
    "# Set the mask values to 0 and 1\n",
    "mask = np.where(mask >= 255, mask, 1)\n",
    "mask = np.where(mask < 255, mask, 0)\n",
    "\n",
    "# Blend the image and save\n",
    "result = blend_img(im2, im1, mask)\n",
    "#save_img('dane_in_cal_game', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
